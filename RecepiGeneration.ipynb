{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fd9bb4ed92d44d1a4a4e6adb0609ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9be13779895a438fb7bb9ef3eda72b2d",
              "IPY_MODEL_df179e9a0d0249cd98bf2e17eec4c6ea",
              "IPY_MODEL_da03a00a2da44873a4784a7c3c41fd03"
            ],
            "layout": "IPY_MODEL_3f3163e79439408b8d68ea291955ae53"
          }
        },
        "9be13779895a438fb7bb9ef3eda72b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_277b9e548f6d4891ad36f65455a470ea",
            "placeholder": "​",
            "style": "IPY_MODEL_b134f96acf2d46bf81e32bc7c30e4031",
            "value": "Map: 100%"
          }
        },
        "df179e9a0d0249cd98bf2e17eec4c6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a3800c12b6a4230a8735bdf6cb42155",
            "max": 13501,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9062354dbb5e4f72b7b55a1808e85482",
            "value": 13501
          }
        },
        "da03a00a2da44873a4784a7c3c41fd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1cd2fbbc1ad416eadd31b778faa17f6",
            "placeholder": "​",
            "style": "IPY_MODEL_5040fc333940479b9ef2ba592177612b",
            "value": " 13501/13501 [00:31&lt;00:00, 587.57 examples/s]"
          }
        },
        "3f3163e79439408b8d68ea291955ae53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "277b9e548f6d4891ad36f65455a470ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b134f96acf2d46bf81e32bc7c30e4031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a3800c12b6a4230a8735bdf6cb42155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9062354dbb5e4f72b7b55a1808e85482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1cd2fbbc1ad416eadd31b778faa17f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5040fc333940479b9ef2ba592177612b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall accelerate -y\n",
        "# !pip install transformers[torch] accelerate -U"
      ],
      "metadata": {
        "id": "8TzZXmGSxVNJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import accelerate\n",
        "\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "print(f\"Accelerate version: {accelerate.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh5PYe9x0on3",
        "outputId": "7648b164-745c-407e-ece9-a1f2ded69834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.41.2\n",
            "Accelerate version: 0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the CSV file\n",
        "dataset = load_dataset('csv', data_files='/content/drive/MyDrive/RecipeGPT/Food Ingredients and Recipe Dataset with Image Name Mapping.csv')\n",
        "\n",
        "# Inspect the dataset\n",
        "print(dataset)\n",
        "\n",
        "\n",
        "\n",
        "# Function to clean the Instructions column\n",
        "def clean_instructions(entry):\n",
        "    # Check if the entry is a string, if not, convert it to an empty string\n",
        "    if isinstance(entry, str):\n",
        "        return entry\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# Extract and clean the Instructions column for each split\n",
        "cleaned_datasets = {}\n",
        "for split in dataset.keys():\n",
        "    cleaned_datasets[split] = dataset[split].map(lambda x: {'text': clean_instructions(x['Instructions'])})\n",
        "\n",
        "\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Add a padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Verify the padding token\n",
        "print(f\"Padding token: {tokenizer.pad_token}, ID: {tokenizer.pad_token_id}\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    tokens = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "    tokens['labels'] = tokens['input_ids'].copy()  # Use input_ids as labels for language modeling\n",
        "    return tokens\n",
        "\n",
        "# Tokenize the cleaned datasets for each split\n",
        "tokenized_datasets = {}\n",
        "for split in cleaned_datasets.keys():\n",
        "    tokenized_datasets[split] = cleaned_datasets[split].map(tokenize_function, batched=True)\n",
        "\n",
        "# Print the tokenized datasets to check\n",
        "print(tokenized_datasets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "1fd9bb4ed92d44d1a4a4e6adb0609ca7",
            "9be13779895a438fb7bb9ef3eda72b2d",
            "df179e9a0d0249cd98bf2e17eec4c6ea",
            "da03a00a2da44873a4784a7c3c41fd03",
            "3f3163e79439408b8d68ea291955ae53",
            "277b9e548f6d4891ad36f65455a470ea",
            "b134f96acf2d46bf81e32bc7c30e4031",
            "6a3800c12b6a4230a8735bdf6cb42155",
            "9062354dbb5e4f72b7b55a1808e85482",
            "c1cd2fbbc1ad416eadd31b778faa17f6",
            "5040fc333940479b9ef2ba592177612b"
          ]
        },
        "id": "s_6dVDtK1VG2",
        "outputId": "0f2b73ef-3658-4340-fcc5-3a0a20d04cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Unnamed: 0', 'Title', 'Ingredients', 'Instructions', 'Image_Name', 'Cleaned_Ingredients'],\n",
            "        num_rows: 13501\n",
            "    })\n",
            "})\n",
            "Padding token: <|endoftext|>, ID: 50256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/13501 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fd9bb4ed92d44d1a4a4e6adb0609ca7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': Dataset({\n",
            "    features: ['Unnamed: 0', 'Title', 'Ingredients', 'Instructions', 'Image_Name', 'Cleaned_Ingredients', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 13501\n",
            "})}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=5,\n",
        "    learning_rate=3e-5,\n",
        ")\n"
      ],
      "metadata": {
        "id": "aAfulAeD1VI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'] if 'validation' in tokenized_datasets else tokenized_datasets['train'],  # Use validation set if available\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Define the path to save the model in Google Drive\n",
        "drive_model_path = '/content/drive/MyDrive/RecipeGPT/fine-tuned-gpt2-instructions'\n",
        "os.makedirs(drive_model_path, exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('./fine-tuned-gpt2-instructions')\n",
        "tokenizer.save_pretrained('./fine-tuned-gpt2-instructions')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "nzo2PpYr2CuW",
        "outputId": "abe0ef6d-b5b6-4225-aeca-531c9804a3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5064' max='5064' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5064/5064 27:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.997200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.779200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine-tuned-gpt2-instructions/tokenizer_config.json',\n",
              " './fine-tuned-gpt2-instructions/special_tokens_map.json',\n",
              " './fine-tuned-gpt2-instructions/vocab.json',\n",
              " './fine-tuned-gpt2-instructions/merges.txt',\n",
              " './fine-tuned-gpt2-instructions/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = './fine-tuned-gpt2-instructions'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "# Define a function to generate recipes\n",
        "def generate_recipe(ingredient_list):\n",
        "    # Prepare the prompt with the ingredient list\n",
        "    prompt = f\"Ingredients: {', '.join(ingredient_list)}\\n\\nRecipe:\\n\"\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Create attention mask\n",
        "    attention_mask = input_ids.ne(tokenizer.pad_token_id).long()\n",
        "\n",
        "    # Generate the recipe\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=300,  # Adjust the max_length as needed\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.3,  # Control the creativity of the generated text\n",
        "        top_p=0.9,  # Use nucleus sampling\n",
        "        do_sample=True,  # Enable sampling to generate more diverse outputs\n",
        "        pad_token_id=tokenizer.eos_token_id  # Set pad_token_id to eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_recipe = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_recipe\n",
        "\n",
        "# Example usage\n",
        "ingredient_list = [\"2 eggs\", \"1 cup of flour\", \"1 cup of milk\", \"1 tsp of baking powder\"]\n",
        "generated_recipe = generate_recipe(ingredient_list)\n",
        "\n",
        "print(generated_recipe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7S9W6w28sdV",
        "outputId": "ea8b24ff-540c-413e-e8c5-478888ea8c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredients: 2 eggs, 1 cup of flour, 1 cup of milk, 1 tsp of baking powder\n",
            "\n",
            "Recipe:\n",
            "\n",
            "Prepare a grill for medium-high heat.\n",
            "Place the chicken breasts on a grill rack set over medium-high heat.\n",
            "While the chicken is cooking, heat the oil in a large skillet over medium-high. Add the onion and cook, stirring occasionally, until softened, about 5 minutes. Add the garlic and cook, stirring, until fragrant, about 3 minutes. Add the tomatoes and cook, stirring, until just beginning to soften, about 2 minutes. Add the tomatoes and cook, stirring, until just beginning to soften, about 2 minutes. Add the remaining 1/2 cup flour and cook, stirring, until just beginning to soften, about 2 minutes. Add the remaining 1/2 cup milk and cook, stirring, until just beginning to soften, about 2 minutes. Add the eggs, 1 cup of flour, 1 tsp of baking powder, and 1/2 tsp salt and cook, stirring, until just beginning to soften, about 2 minutes. Add the remaining 1/2 cup milk and cook, stirring, until just beginning to soften, about 2 minutes. Add the tomatoes and cook, stirring, until just beginning to soften, about 2 minutes. Add the remaining 1/2 cup milk and cook, stirring, until just beginning to soften, about 2 minutes. Add the remaining 1/2 cup milk and cook, stirring, until just\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "SjWrcsfJ8snN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the CSV file\n",
        "dataset = load_dataset('csv', data_files='/content/drive/MyDrive/RecipeGPT/Food Ingredients and Recipe Dataset with Image Name Mapping.csv')\n",
        "\n",
        "# Create a train-validation split if it does not exist\n",
        "if 'train' not in dataset or 'validation' not in dataset:\n",
        "    train_test_data = dataset['train'].train_test_split(test_size=0.1)\n",
        "    dataset = DatasetDict({\n",
        "        'train': train_test_data['train'],\n",
        "        'validation': train_test_data['test']\n",
        "    })\n",
        "\n",
        "# Function to clean the Instructions column\n",
        "def clean_instructions(entry):\n",
        "    # Check if the entry is a string, if not, convert it to an empty string\n",
        "    if isinstance(entry, str):\n",
        "        return entry\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# Extract and clean the Instructions column for each split\n",
        "cleaned_datasets = {}\n",
        "for split in dataset.keys():\n",
        "    cleaned_datasets[split] = dataset[split].map(lambda x: {'text': clean_instructions(x['Instructions'])})\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Add a padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    tokens = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "    tokens['labels'] = tokens['input_ids'].copy()  # Use input_ids as labels for language modeling\n",
        "    return tokens\n",
        "\n",
        "# Tokenize the cleaned datasets for each split\n",
        "tokenized_datasets = {}\n",
        "for split in cleaned_datasets.keys():\n",
        "    tokenized_datasets[split] = cleaned_datasets[split].map(tokenize_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,  # Reduced batch size\n",
        "    per_device_eval_batch_size=8,   # Reduced batch size\n",
        "    logging_steps=500,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=3e-5,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'] if 'validation' in tokenized_datasets else tokenized_datasets['train'],  # Use validation set if available\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Define the path to save the model in Google Drive\n",
        "drive_model_path = '/content/drive/MyDrive/RecipeGPT/fine-tuned-gpt2-instructions'\n",
        "os.makedirs(drive_model_path, exist_ok=True)\n",
        "\n",
        "# Save the model and tokenizer to Google Drive\n",
        "model.save_pretrained(drive_model_path)\n",
        "tokenizer.save_pretrained(drive_model_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "YRxTTU298sqF",
        "outputId": "74e74cd1-91a8-42fc-c25b-7fb4418ffac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4557' max='4557' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4557/4557 26:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.239700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.966500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.885400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.824700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.786700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.780800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.772800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to /content/drive/My Drive/fine-tuned-gpt2-instructions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the model"
      ],
      "metadata": {
        "id": "slmwNMgdav4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save the model in Google Drive\n",
        "drive_model_path = '/content/drive/MyDrive/RecipeGPT/fine-tuned-gpt2-instructions'\n",
        "os.makedirs(drive_model_path, exist_ok=True)\n",
        "\n",
        "# Save the model and tokenizer to Google Drive\n",
        "model.save_pretrained(drive_model_path)\n",
        "tokenizer.save_pretrained(drive_model_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjQ9zajs8ssZ",
        "outputId": "d2b5eb58-6bdc-4063-db95-c28cd2fc86ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to /content/drive/MyDrive/RecipeGPT/fine-tuned-gpt2-instructions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Recipes"
      ],
      "metadata": {
        "id": "fKbyhswJadyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = '/content/drive/MyDrive/RecipeGPT/fine-tuned-gpt2-instructions'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "# Add a padding token if it's not already set\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "id": "z6miD3pxWv9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recipe(ingredient_list, max_length=300, num_return_sequences=1, temperature=0.7, top_p=0.9):\n",
        "    # Prepare the prompt with the ingredient list\n",
        "    prompt = f\"Ingredients: {', '.join(ingredient_list)}\\n\\nRecipe:\\n\"\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "    # Generate the recipe\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "Et9yy2lmWv_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example ingredient list\n",
        "ingredient_list = [\"2 eggs\", \"1 cup of flour\", \"1 cup of milk\", \"1 tsp of baking powder\"]\n",
        "\n",
        "# Generate the recipe\n",
        "generated_recipe = generate_recipe(ingredient_list)\n",
        "\n",
        "print(generated_recipe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix6e4CetWwCY",
        "outputId": "30edb4a5-503a-4168-a1b5-cd5f306695fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredients: 2 eggs, 1 cup of flour, 1 cup of milk, 1 tsp of baking powder\n",
            "\n",
            "Recipe:\n",
            "Place 1/4 cup of flour, 1/2 cup of milk, 1 tsp of baking powder in a large bowl. Mix in 1/4 cup of water. Add yeast and whisk until smooth.\n",
            "Divide dough in half and roll each half into a ball. Transfer to a 13x9\" baking dish. Cover and chill for at least 2 hours.\n",
            "To make the cake: Place the eggs and milk in a large bowl and stir in the flour, baking powder, salt, and pepper. Whisk until combined.\n",
            "Using an electric mixer, beat the flour mixture until smooth, about 5 minutes. With the mixer on low speed, gradually add the eggs and milk and beat until combined.\n",
            "Divide dough in half and roll each half into a ball. Cover and chill for at least 2 hours.\n",
            "To make the filling: Place the dough in a large bowl and stir in the egg mixture. Cover and chill for at least 2 hours.\n",
            "To make the filling: Place the dough in a large bowl and stir in the sugar and vanilla. Whisk until combined.\n",
            "Add the milk and vanilla mixture and mix until incorporated.\n",
            "To make the filling: Place the flour mixture in a large bowl and stir in the baking powder and salt. Whisk until combined.\n",
            "To make the filling: Place the dough in a large bowl and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ingredient_list = [\"200g spaghetti\", \"100g pancetta\", \"2 large eggs\", \"50g pecorino cheese\", \"50g parmesan\", \"2 cloves of garlic\", \"Salt\", \"Black pepper\"]\n",
        "generated_recipe = generate_recipe(ingredient_list)\n",
        "print(generated_recipe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG4ARkwZWwHU",
        "outputId": "dee30735-8fb1-4821-afef-f6c059627fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredients: 200g spaghetti, 100g pancetta, 2 large eggs, 50g pecorino cheese, 50g parmesan, 2 cloves of garlic, Salt, Black pepper\n",
            "\n",
            "Recipe:\n",
            "Pizza Dough:\n",
            "Pizza Dough:\n",
            "1/2 cup flour, 1 tsp. salt, and 2 cups water\n",
            "1/2 cup sugar\n",
            "3/4 cup water\n",
            "2 tsp. pepper\n",
            "Preheat oven to 350°F. Butter a 9x13\" baking dish.\n",
            "In a medium bowl, whisk together flour, baking powder, baking soda, and salt.\n",
            "In a medium bowl, combine remaining 1/2 cup sugar, 1/2 cup flour, baking soda, and salt.\n",
            "In a medium bowl, combine eggs, remaining 1/2 cup sugar, and 1/2 cup water.\n",
            "In a medium bowl, whisk together pasta, egg mixture, Parmesan, and garlic.\n",
            "In a large bowl, whisk together breadcrumbs and remaining 1/2 cup sugar, then add flour mixture.\n",
            "In a large bowl, whisk together remaining 1/2 cup sugar, 1/2 cup flour, and salt.\n",
            "In a medium bowl, whisk together egg mixture, Parmesan, and garlic.\n",
            "In a large bowl, whisk together breadcrumbs and remaining 1/2 cup sugar, then add breadcrumbs and remaining 1/2 cup sugar.\n",
            "Pour batter into prepared dish. Bake until cheese is bubbly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ingredient_list = [\"1 kg chicken pieces\", \"2 onions\", \"3 tomatoes\", \"2 teaspoons ginger-garlic paste\", \"2 teaspoons chili powder\", \"1 teaspoon turmeric powder\", \"2 teaspoons garam masala\", \"Salt\", \"Oil\"]\n",
        "generated_recipe = generate_recipe(ingredient_list)\n",
        "print(generated_recipe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEMZt4tNVGi6",
        "outputId": "658eac63-c15c-4db6-b422-d80af29faf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredients: 1 kg chicken pieces, 2 onions, 3 tomatoes, 2 teaspoons ginger-garlic paste, 2 teaspoons chili powder, 1 teaspoon turmeric powder, 2 teaspoons garam masala, Salt, Oil\n",
            "\n",
            "Recipe:\n",
            "Chile: 1/4 cup cumin, 1/4 cup paprika, 1/4 teaspoon paprika powder, 1/4 teaspoon black pepper, 1/4 teaspoon cayenne, 1/4 teaspoon salt, 1/2 teaspoon black pepper, 1/4 teaspoon black pepper paste, 1/4 teaspoon coriander, 1/4 teaspoon black pepper paste, 1/4 teaspoon coriander, 1/2 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon coriander paste, 1/4 teaspoon cori\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ingredient_list = [\"1 kg beef chuck, cut into chunks\", \"2 tablespoons flour\", \"2 tablespoons olive oil\", \"1 large onion\", \"2 cloves garlic\", \"3 carrots\", \"2 potatoes\", \"2 cups beef broth\", \"1 cup red wine\", \"2 bay leaves\", \"Salt\", \"Pepper\"]\n",
        "generated_recipe = generate_recipe(ingredient_list)\n",
        "print(generated_recipe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwK4ykB6aSTq",
        "outputId": "fc87d68d-fd08-4276-9228-e70d6ca9714e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredients: 1 kg beef chuck, cut into chunks, 2 tablespoons flour, 2 tablespoons olive oil, 1 large onion, 2 cloves garlic, 3 carrots, 2 potatoes, 2 cups beef broth, 1 cup red wine, 2 bay leaves, Salt, Pepper\n",
            "\n",
            "Recipe:\n",
            "Preheat oven to 300°F. Cook beef in a large pot of boiling salted water until tender and cooked through, about 5 minutes per side. Drain. Transfer to a bowl with a slotted spoon and let cool.\n",
            "Drain beef.\n",
            "Combine all ingredients except beef in a large bowl and toss with a fork. Season to taste with salt and pepper.\n",
            "Divide beef into 4 portions and toss to coat. Let sit until ready to use.\n",
            "Divide beef between 2 large bowls and toss to coat.\n"
          ]
        }
      ]
    }
  ]
}